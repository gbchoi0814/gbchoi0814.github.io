---
layout: post
title: (논문리뷰) Darts 
---
- 작성완료된 포스팅

### Reference
- Ahmed, K., \& Torresani, L. (2017). Connectivity learning in multi-branch networks. arXiv preprint arXiv:1709.09582.
- Liu, C., Zoph, B., Neumann, M., Shlens, J., Hua, W., Li, L. J., ... & Murphy, K. (2018). Progressive neural architecture search. In Proceedings of the European Conference on Computer Vision (ECCV) (pp. 19-34).
- Liu, H., Simonyan, K., \& Yang, Y. (2018). Darts: Differentiable architecture search. arXiv preprint arXiv:1806.09055.
- Real, E., Aggarwal, A., Huang, Y., \& Le, Q. V. (2018). Regularized evolution for image classifier architecture search. arXiv preprint arXiv:1802.01548.
- Saxena, S., \& Verbeek, J. (2016). Convolutional neural fabrics. In Advances in Neural Information Processing Systems (pp. 4053-4061).
- Shin, R., Packer, C., \& Song, D. (2018). Differentiable Neural Network Architecture Search.
- Zoph, B., \& Le, Q. V. (2016). Neural architecture search with reinforcement learning. arXiv preprint arXiv:1611.01578.
- Zoph, B., Vasudevan, V., Shlens, J., \& Le, Q. V. (2018). Learning transferable architectures for scalable image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 8697-8710).

### Introduction 
- 본 포스팅은 ***Liu, H., Simonyan, K., \& Yang, Y. (2018). Darts: Differentiable architecture search. arXiv preprint arXiv:1806.09055*** 을 리뷰한 것이다. 해당논문은 https://arxiv.org/abs/1806.09055에서 확인할 수 있다. 
- 이 논문은 딥러닝 아키텍쳐를 자동으로 골라주는 방법에 대하여 논의한 것이다. 예를들면 특정 데이터를 분석하는 아키텍처를 구성할때 노드와 노드사이를 $3\times 3$ convolution으로 연결할지 혹은 $5 \times 5$ max pooling으로 연결할지등을 알아서 선택해준다는 것이다. 
- 이 논문은 즉 ''인공지능을 만드는 인공지능''에 대해서 논의한다고 볼 수 있다. 
- 개인적으로 ''인간은 정말 끝없이 게을러지고 싶어하는구나, 이제 하다못해 인공지능을 만드는 것도 귀찮아서 그것까지 인공지능에게 시키는구나..'' 하는 생각이 들게 만드는 논문이었다. 
- 처음에는 ''인공지능을 만드는 인공지능''을 설계한다는 것이 다소 허황되게 느껴지기도 했는데 논문을 읽어보니 좀 말이 되는것 같기도 하다. 


### Darts (Differentialbe Architecture Search)

***Search Space***

- 분석하고자 하는 자료는 기본적으로 방향성비순환그래프(directed acyclic graph)형태로 표현가능하다고 생각한다. 
- 방향성 비순환 그래프의 대표적인 예는 시계열 자료를 생각할 수 있다. 
- 시계열 자료는 $t$시점에서 $t+1$의 시점으로의 방향성이 있으나 순환하지 않는다. 
- 이때 순환하지 않는다는 말은 화살표를 따라서 어떠한 경로로 이동해도 자기자신으로 돌아올 수 없다는 의미이다. 

