---
layout: post
title: 통계학, 매우 얕은 지식 (1)
subtitle: *머신러닝의 과업 및 계파*
---

### 머신러닝 과업들

이번절에는 지도학습과 비지도 학습의 전형적인 과업에 대하여 소개하겠다. 

***Regression***
- $y=f(x)$형태의 모델임. 
- $\\{(x_i,y_i)\\}_ {i=1}^{n}$에서 $f$를 학습하는 방식임. 
- 회귀는 결국 function estimation. 

***Classification***
- $y=f(x)$형태의 자료에서 $y=0$ 또는 $1$인 형태이므로 회귀모델로 볼 수 있음. 

***Anomaly detection***
- 주어진 입력표본 $\\{x_i\\}_ {i=1}^{n}$에 포함된 비정상적인 값을 발견하는 문제이다. 
- 밀집해있는 자료를 정상으로 간주하고 그 군집으로부터 멀리 떨어진 자료를 비정상으로 간주한다. (Line형태로 군집이 이루어지면 어쩔꺼야? ㅋㅋ) 

***Clustering*** 
- 표본간의 유사도를 측정하는 방법을 적절히 선택하는 것이 중요하다. 
- 이때 그래프라플라시안을 활용하면 좋을듯? smoothness개념 
- hst에서도 전체 smoothness를 정의하는 어떠한 방법이 있으면 좋겠네. Total variation의 개념과도 연결되는것 같다? 

***Dimensionality reduction***
- 입력차원 $\\{x_i\\}_ {i=1}^{n}$의 차원이 매우 클때 그것을 낮은차원의 자료들 $\\{z_i\\}_ {i=1}^{n}$로 바꾸는 방법
- 선형차원축소의 경우 가로로 긴 행렬 ${\bf T}$를 사용하여 $z_i={\bf T}x_i$와 같은 방식으로 쓸 수 있음. 행렬이 가로로 긴 이후는 $z_i$의 차원이 $x_i$보다 작아야 하기 때문임. 
- 가령 예를 들어서 $x_i=[1,2,4,5,8]$과 같은 자료가 있다고 하자. 이때 ${\bf x}$의 차원은 5이다. 그러면 ${\bf T}$를 $5\times 2$와 같은 행렬을 잡아와서 $z_i={\bf T}x_i$와 같이 쓸 수 있는데 이러면 $z_i$의 차원은 2가 되고 ${\bf T}$는 5차원자료를 2차원으로 줄이는 변환이 된다. 

### 머신러닝의 계파 

***생성적분류 vs 식별적분류***
- $28\times 28$-pixel 의 이미지자료가 있다고 하자. 따라서 이경우 ${\bf X}_ {n\times 784}$가 된다. 
- $y_{n\times 1}$이라고 하고, $y \in \\{0,\dots,9\\}$라고 하자. 
  \begin{align}
  \hat{y}=\underset{y}{\operatorname{argmax}} p(y|x)
  \end{align}

***빈도주의 vs 베이지안***
